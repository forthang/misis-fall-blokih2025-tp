# ü§ñ Reinforcement Learning: –û—Ç —Ç–µ–æ—Ä–∏–∏ –∫ –ø—Ä–∞–∫—Ç–∏–∫–µ

<div align="center">

![Python](https://img.shields.io/badge/Python-3.8+-blue?style=for-the-badge&logo=python)
![NumPy](https://img.shields.io/badge/NumPy-Scientific-013243?style=for-the-badge&logo=numpy)
![Pygame](https://img.shields.io/badge/Pygame-Visualization-green?style=for-the-badge)

**–ö—É—Ä—Å–æ–≤–∞—è —Ä–∞–±–æ—Ç–∞ –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—é**

*–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º*

[–¢–µ–æ—Ä–∏—è](#-—Ç–µ–æ—Ä–∏—è) ‚Ä¢ [GridWorld](#-gridworld) ‚Ä¢ [Walker](#-walker) ‚Ä¢ [–ó–∞–ø—É—Å–∫](#-–∑–∞–ø—É—Å–∫) ‚Ä¢ [–ó–∞—â–∏—Ç–∞](DEFENSE.md)

</div>

---

## üìñ –û –ø—Ä–æ–µ–∫—Ç–µ

–ü—Ä–æ–µ–∫—Ç –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –¥–≤–∞ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–∞ Reinforcement Learning:

| –ó–∞–¥–∞—á–∞ | –ê–ª–≥–æ—Ä–∏—Ç–º | –°–ª–æ–∂–Ω–æ—Å—Ç—å |
|--------|----------|-----------|
| **GridWorld** ‚Äî –Ω–∞–≤–∏–≥–∞—Ü–∏—è –ø–æ —Å–µ—Ç–∫–µ | Q-Learning | –î–∏—Å–∫—Ä–µ—Ç–Ω—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∏ –¥–µ–π—Å—Ç–≤–∏—è |
| **Walker** ‚Äî –æ–±—É—á–µ–Ω–∏–µ —Ö–æ–¥—å–±–µ | PPO | –ù–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è, —Ñ–∏–∑–∏–∫–∞ |

---

## üß† –¢–µ–æ—Ä–∏—è

### –ß—Ç–æ —Ç–∞–∫–æ–µ Reinforcement Learning?

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    –¥–µ–π—Å—Ç–≤–∏–µ     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  –ê–ì–ï–ù–¢  ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ    –°–†–ï–î–ê    ‚îÇ
‚îÇ         ‚îÇ ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  —Å–æ—Å—Ç–æ—è–Ω–∏–µ +    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              –Ω–∞–≥—Ä–∞–¥–∞
```

**–ê–≥–µ–Ω—Ç** —É—á–∏—Ç—Å—è –º–µ—Ç–æ–¥–æ–º –ø—Ä–æ–± –∏ –æ—à–∏–±–æ–∫:
- –î–µ–ª–∞–µ—Ç –¥–µ–π—Å—Ç–≤–∏–µ ‚Üí –ø–æ–ª—É—á–∞–µ—Ç –Ω–∞–≥—Ä–∞–¥—É/—à—Ç—Ä–∞—Ñ
- –ó–∞–ø–æ–º–∏–Ω–∞–µ—Ç, —á—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç, –∞ —á—Ç–æ –Ω–µ—Ç
- –°–æ –≤—Ä–µ–º–µ–Ω–µ–º –Ω–∞—Ö–æ–¥–∏—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é

### –ö–ª—é—á–µ–≤—ã–µ —Ñ–æ—Ä–º—É–ª—ã

**Q-Learning:**
$$Q(s,a) \leftarrow Q(s,a) + \alpha [r + \gamma \max_{a'} Q(s',a') - Q(s,a)]$$

**PPO Objective:**
$$L^{CLIP} = \mathbb{E}[\min(r_t \hat{A}_t, \text{clip}(r_t, 1-\epsilon, 1+\epsilon) \hat{A}_t)]$$

> üìö –ü–æ–¥—Ä–æ–±–Ω–∞—è —Ç–µ–æ—Ä–∏—è –∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è: [DEFENSE.md](DEFENSE.md)

---

## üéÆ GridWorld

### –û–ø–∏—Å–∞–Ω–∏–µ

–ê–≥–µ–Ω—Ç –Ω–∞ —Å–µ—Ç–∫–µ 5√ó5 –∏—â–µ—Ç –ø—É—Ç—å –∫ —Ü–µ–ª–∏, –∏–∑–±–µ–≥–∞—è –ø—Ä–µ–ø—è—Ç—Å—Ç–≤–∏–π.

```
‚îå‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îê
‚îÇ A ‚îÇ ‚Üí ‚îÇ ‚Üí ‚îÇ ‚Üì ‚îÇ . ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚î§
‚îÇ . ‚îÇ X ‚îÇ . ‚îÇ ‚Üì ‚îÇ . ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚î§
‚îÇ . ‚îÇ . ‚îÇ X ‚îÇ ‚Üì ‚îÇ . ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚î§
‚îÇ . ‚îÇ X ‚îÇ . ‚îÇ ‚Üí ‚îÇ ‚Üì ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚î§
‚îÇ . ‚îÇ . ‚îÇ . ‚îÇ . ‚îÇ G ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îò
```

### –ù–∞–≥—Ä–∞–¥—ã

| –°–æ–±—ã—Ç–∏–µ | –ù–∞–≥—Ä–∞–¥–∞ |
|---------|---------|
| üéØ –¶–µ–ª—å | +10 |
| üí• –ü—Ä–µ–ø—è—Ç—Å—Ç–≤–∏–µ | -5 |
| üö∂ –®–∞–≥ | -0.1 |

### –ó–∞–ø—É—Å–∫

```bash
python train_visual.py --episodes 500 --delay 30
```

---

## üö∂ Walker

### –û–ø–∏—Å–∞–Ω–∏–µ

–î–≤—É–Ω–æ–≥–∏–π –ø–µ—Ä—Å–æ–Ω–∞–∂ —É—á–∏—Ç—Å—è —Ö–æ–¥–∏—Ç—å, —É–±–µ–≥–∞—è –æ—Ç **–ª—É—á–∞ —Å–º–µ—Ä—Ç–∏**.

```
        ‚óã ‚Üê –ì–æ–ª–æ–≤–∞
        ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îê ‚Üê –¢–æ—Ä—Å
    ‚óØ       ‚óØ ‚Üê –ë—ë–¥—Ä–∞
   /         \
  ‚óØ           ‚óØ ‚Üê –ö–æ–ª–µ–Ω–∏
  ‚îÇ           ‚îÇ
  ‚óè           ‚óè ‚Üê –°—Ç–æ–ø—ã
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚óÄ‚ñà‚ñà‚ñà‚ñà –õ–£–ß –°–ú–ï–†–¢–ò (—É—Å–∫–æ—Ä—è–µ—Ç—Å—è!)
```

### –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏

- **8 –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π** –æ–±—É—á–∞—é—Ç—Å—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
- **–õ—É—á —Å–º–µ—Ä—Ç–∏** –¥–æ–≥–æ–Ω—è–µ—Ç –∏ —É—Å–∫–æ—Ä—è–µ—Ç—Å—è
- **–§–∏–∑–∏–∫–∞** ‚Äî —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ —Å—É—Å—Ç–∞–≤—ã –∏ –≥—Ä–∞–≤–∏—Ç–∞—Ü–∏—è
- **PPO** ‚Äî –Ω–µ–π—Ä–æ—Å–µ—Ç—å —É–ø—Ä–∞–≤–ª—è–µ—Ç 4 —Å—É—Å—Ç–∞–≤–∞–º–∏

### –ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ —Å–æ—Å—Ç–æ—è–Ω–∏–π (10D)

```
[—Å–∫–æ—Ä–æ—Å—Ç—å, –±–µ–¥—Ä–æ_–ª, –±–µ–¥—Ä–æ_–ø, –∫–æ–ª–µ–Ω–æ_–ª, –∫–æ–ª–µ–Ω–æ_–ø,
 —Å–∫–æ—Ä_–±–µ–¥—Ä–∞_–ª, —Å–∫–æ—Ä_–±–µ–¥—Ä–∞_–ø, —Å–∫–æ—Ä_–∫–æ–ª–µ–Ω–∞_–ª, —Å–∫–æ—Ä_–∫–æ–ª–µ–Ω–∞_–ø,
 —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ_–¥–æ_–ª—É—á–∞]
```

### –§—É–Ω–∫—Ü–∏—è –Ω–∞–≥—Ä–∞–¥—ã

```python
reward = –¥–≤–∏–∂–µ–Ω–∏–µ √ó 5           # –ì–ª–∞–≤–Ω–æ–µ ‚Äî –∏–¥—Ç–∏ –≤–ø–µ—Ä—ë–¥
       + —Å–∫–æ—Ä–æ—Å—Ç—å √ó 2           # –ë–æ–Ω—É—Å –∑–∞ –±—ã—Å—Ç—Ä–æ—Ç—É
       - 0.5 (–µ—Å–ª–∏ —Å—Ç–æ–∏—Ç)       # –®—Ç—Ä–∞—Ñ –∑–∞ –±–µ–∑–¥–µ–ª—å–µ
       - 1.0 (–µ—Å–ª–∏ –ø—Ä–∏—Å–µ–ª)      # –®—Ç—Ä–∞—Ñ –∑–∞ –ø—Ä–∏—Å–µ–¥–∞–Ω–∏–µ
       - 20 (–ø–∞–¥–µ–Ω–∏–µ)
       - 30 (–ø–æ–π–º–∞–Ω –ª—É—á–æ–º)
```

### –ó–∞–ø—É—Å–∫

```bash
# –û–±—É—á–µ–Ω–∏–µ
python train_walker.py --episodes 300 --delay 5

# –î–µ–º–æ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
python demo_walker.py

# –ì—Ä–∞—Ñ–∏–∫–∏
python visualize.py --type walker
```

---

## üîß –ò—Å—Ç–æ—Ä–∏—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏

### v1.0 ‚Äî GridWorld
‚úÖ Q-Learning —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π

### v2.0 ‚Äî Walker (–ø–µ—Ä–≤—ã–µ –ø–æ–ø—ã—Ç–∫–∏)
üêõ **–ë–∞–≥:** –ü–µ—Ä—Å–æ–Ω–∞–∂ –≤–∏—Å–µ–ª –≤ –≤–æ–∑–¥—É—Ö–µ  
‚úÖ **–§–∏–∫—Å:** –ü–æ–∑–∏—Ü–∏—è –≤—ã—á–∏—Å–ª—è–µ—Ç—Å—è –æ—Ç —Å—Ç–æ–ø

üêõ **–ë–∞–≥:** –ù–æ–≥–∏ —É—Ö–æ–¥–∏–ª–∏ –ø–æ–¥ –∑–µ–º–ª—é  
‚úÖ **–§–∏–∫—Å:** –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ Y-–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç

### v3.0 ‚Äî –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
‚úÖ 8 –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ  
‚úÖ –ü–æ–∫–∞–∑ –ª—É—á—à–µ–≥–æ, –æ—Å—Ç–∞–ª—å–Ω—ã–µ ‚Äî –ø—Ä–∏–∑—Ä–∞–∫–∏

### v3.1 ‚Äî –õ—É—á —Å–º–µ—Ä—Ç–∏
‚úÖ –ú–æ—Ç–∏–≤–∞—Ü–∏—è –¥–≤–∏–≥–∞—Ç—å—Å—è –±—ã—Å—Ç—Ä–µ–µ  
‚úÖ –õ—É—á —É—Å–∫–æ—Ä—è–µ—Ç—Å—è —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º

### v3.2 ‚Äî –ê–Ω—Ç–∏-—á–∏—Ç–∏–Ω–≥
üêõ **–ë–∞–≥:** –ü–µ—Ä—Å–æ–Ω–∞–∂–∏ –ø—Ä–∏—Å–µ–¥–∞–ª–∏ –∏ –Ω–µ –¥–≤–∏–≥–∞–ª–∏—Å—å  
‚úÖ **–§–∏–∫—Å:** –®—Ç—Ä–∞—Ñ –∑–∞ –ø—Ä–∏—Å–µ–¥–∞–Ω–∏–µ –∏ –±–µ–∑–¥–µ–π—Å—Ç–≤–∏–µ

---

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
rl-coursework/
‚îú‚îÄ‚îÄ README.md              # –≠—Ç–æ—Ç —Ñ–∞–π–ª
‚îú‚îÄ‚îÄ DEFENSE.md             # –ú–∞—Ç–µ—Ä–∏–∞–ª—ã –¥–ª—è –∑–∞—â–∏—Ç—ã
‚îú‚îÄ‚îÄ requirements.txt
‚îÇ
‚îú‚îÄ‚îÄ environments/
‚îÇ   ‚îú‚îÄ‚îÄ gridworld.py       # –°–µ—Ç–∫–∞ 5√ó5
‚îÇ   ‚îî‚îÄ‚îÄ walker.py          # –•–æ–¥—å–±–∞ + –ª—É—á
‚îÇ
‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îú‚îÄ‚îÄ qlearning.py       # Q-Learning
‚îÇ   ‚îî‚îÄ‚îÄ ppo.py             # PPO
‚îÇ
‚îú‚îÄ‚îÄ models/                # –°–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
‚îú‚îÄ‚îÄ logs/                  # –ú–µ—Ç—Ä–∏–∫–∏
‚îÇ
‚îú‚îÄ‚îÄ train_visual.py        # –û–±—É—á–µ–Ω–∏–µ GridWorld
‚îú‚îÄ‚îÄ train_walker.py        # –û–±—É—á–µ–Ω–∏–µ Walker
‚îú‚îÄ‚îÄ demo_walker.py         # –î–µ–º–æ –º–æ–¥–µ–ª–∏
‚îî‚îÄ‚îÄ visualize.py           # –ì—Ä–∞—Ñ–∏–∫–∏
```

---

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### –£—Å—Ç–∞–Ω–æ–≤–∫–∞ (Arch Linux)

```bash
sudo pacman -S python-numpy python-matplotlib python-pygame
```

### –ó–∞–ø—É—Å–∫

```bash
cd ~/rl-coursework

# GridWorld
python train_visual.py --episodes 500

# Walker
python train_walker.py --episodes 300

# –ì—Ä–∞—Ñ–∏–∫–∏
python visualize.py
```

### –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ

| –ö–ª–∞–≤–∏—à–∞ | –î–µ–π—Å—Ç–≤–∏–µ |
|---------|----------|
| `SPACE` | –ü–∞—É–∑–∞ |
| `+/-` | –°–∫–æ—Ä–æ—Å—Ç—å |
| `S` | –°–æ—Ö—Ä–∞–Ω–∏—Ç—å |
| `R` | –†–µ—Å—Ç–∞—Ä—Ç |
| `Q` | –í—ã—Ö–æ–¥ |

---

## üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã

### GridWorld
- **Success Rate:** >95% –ø–æ—Å–ª–µ 500 —ç–ø–∏–∑–æ–¥–æ–≤
- **–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø—É—Ç—å:** 8 —à–∞–≥–æ–≤

### Walker
- **–¶–µ–ª—å:** —É–±–µ–∂–∞—Ç—å –∫–∞–∫ –º–æ–∂–Ω–æ –¥–∞–ª—å—à–µ
- **–†–µ–∫–æ—Ä–¥:** –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –æ–±—É—á–µ–Ω–∏—è
- **–õ—É—á:** –Ω–∞—á–∏–Ω–∞–µ—Ç —Å–æ —Å–∫–æ—Ä–æ—Å—Ç–∏ 1.0, —É—Å–∫–æ—Ä—è–µ—Ç—Å—è

---

## üìö –õ–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞

1. Sutton & Barto ‚Äî *Reinforcement Learning: An Introduction*
2. Schulman et al. ‚Äî *Proximal Policy Optimization*
3. Mnih et al. ‚Äî *Human-level control through deep RL*

---

<div align="center">

**üìÑ [–ú–∞—Ç–µ—Ä–∏–∞–ª—ã –¥–ª—è –∑–∞—â–∏—Ç—ã ‚Üí](DEFENSE.md)**

*Q-Learning ‚Ä¢ PPO ‚Ä¢ Pygame ‚Ä¢ NumPy*

</div>
